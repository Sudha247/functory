\documentclass[twoside]{article}

\usepackage{actes,comment,amsmath,graphicx,color,url}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}

\newcommand{\Ocaml}{OCaml}
\newcommand{\functory}{\textsf{Functory}}
\newcommand{\JoCaml}{Jo{\&\!}Caml}
\newcommand{\unix}{\textsc{Unix}}
\newcommand{\oeuvre}{\oe uvre}
\newcommand{\coeur}{c\oe ur}
\newcommand{\coeurs}{c\oe urs}


\title{Functory: Une bibliothèque de calcul distribué \\ pour
  Objective Caml\footnotetext{Ce
    travail a été réalisé en partie dans le cadre du projet U3CAT
    (\emph{Unification of Critical C Code Analysis Techniques},
    ANR-08-SEGI-021).}} 

\author{Jean-Christophe Filli\^{a}tre$^{1,2,3}$ \& K. Kalyanasundaram$^3$}

\titlehead{Functory}%  a droite (page impaire)

\authorhead{Filliâtre \& Kalyanasundaram}% a gauche (page paire)

\affiliation{\begin{tabular}{rr} 
\\ 1:  CNRS / LRI UMR 8623 F-91405 Orsay
\\ 2:  Université Paris Sud F-91405 Orsay
\\ 3:  INRIA Saclay -- Île-de-France F-91893 Orsay
\\ {\tt filliatr@lri.fr},  
   {\tt kalyan.krishnamani@inria.fr}
\end{tabular}}

\begin{document}
\setcounter{page}{1}
\maketitle

\begin{abstract}
  Cet article présente \functory, une bibliothèque de calcul distribué
  pour Objective Caml. Les principales caractéristiques de cette
  bibliothèque sont (1) une interface polymorphe, (2) plusieurs
  réalisations correspondant à des contextes d'utilisation différents
  et (3) un mécanisme de tolérance aux pannes.
  Cet article détaille la conception et la réalisation de Functory et
  montre son potentiel sur de nombreux exemples.
\end{abstract}

\section{Introduction}

Cet article présente \functory, une bibliothèque de calcul distribué
pour Objective Caml. Initialement, ce travail a été motivé par des
besoins de calcul au sein de notre équipe de recherche, ProVal.
Nos applications en vérification déductive de programmes incluent
notamment la validation de très nombreuses formules logiques par des
démonstrateurs automatiques variés~\cite{filliatre07cav}.
Nos moyens de calcul consistent en quelques machines très puissantes
(typiquement 8 ou 16 \coeurs) et plusieurs ordinateurs de bureau
(typiquement 2 \coeurs). Aucune bibliothèque ne nous permettait de
tirer facilement partie de cette infrastructure de calcul dans notre
langage préféré. C'est pourquoi nous avons conçu et réalisé la
bibliothèque \functory\ qui est le sujet de cet article.
Cette bibliothèque est réalisée pour \Ocaml\ mais pourrait facilement
être adaptée pour tout autre langage fonctionnel.

\functory\ n'est pas une bibliothèque qui aide l'utilisateur à
paralléliser ses calculs. Son rôle consiste plutôt à offrir des
facilités pour distribuer, de manière sûre, des calculs déjà
identifiés comme indépendants. En particulier, \functory\ offre
plusieurs interfaces génériques pour distribuer des calculs sur différents
\coeurs\ d'une même machine ou sur un réseau de machines. Ceci
correspond exactement au contexte qui a motivé la construction de
cette bibliothèque mais aussi, très probablement, à celui de
nombreuses autres applications.
Les principales caractéristiques de \functory\ sont les suivantes :
\begin{itemize}
\item \emph{généricité} : les
  traits fonctionnels que sont l'ordre
  supérieur et le polymorphisme sont exploités pour fournir un maximum
  de généricité ;
\item \emph{simplicité} : on passe d'un calcul séquentiel à un
  calcul multi-\coeurs puis à un calcul en réseau en ne modifiant
  que quelques lignes dans le code ;
\item \emph{distribution et tolérance aux pannes} : l'intégralité de
  la gestion de la distribution et de la tolérance aux pannes est
  prise en charge par la bibliothèque.
\end{itemize}
Bien que \functory\ a été écrite avec un soucis de généralité, elle ne
vise pas les grandes grappes de serveurs ou les fermes de calcul. 
Elle s'adresse plutôt aux équipes de recherche qui souhaitent
exploiter rapidement des capacités de calcul existantes allant d'un
simple ordinateur de bureau à un réseau de machines.
Le reste de cette introduction décrit notre approche du calcul
distribué dans le contexte d'un langage fonctionnel.

\paragraph{Calcul distribué.}
Initialement inspirée par la bibliothèque
MapReduce\footnote{Ironiquement, l'approche de Google a été elle-même
  inspirée par la programmation fonctionnelle.} de
Google~\cite{mapreduce}, notre approche lui emprunte beaucoup de
vocabulaire.
La bibliothèque \functory\ est centrée autour de la notion de
\emph{tâche}. Les tâches représentent les calculs atomiques pouvant
être réalisés de manière indépendante.
Elles sont traitées par un \emph{patron} et des \emph{ouvriers}
(respectivement \emph{master} et \emph{workers} en anglais).
Les ouvriers représentent les capacités de calcul qui effectuent les
tâches. Ils sont
matérialisés par un ou plusieurs programmes, s'exécutant en parallèle
sur une ou plusieurs machines.
Le rôle du patron consiste à distribuer les tâches auprès des ouvriers
et à récolter les résultats. Il est matérialisé par un unique
programme s'exécutant de manière séquentielle.

Une partie importante du travail de \functory\ consiste en la
transmission des tâches et de leurs résultats. 
Ceci implique leur sérialisation (en anglais
\emph{marshalling}) à travers le
réseau, sur un parc potentiellement hétérogène en termes
d'architectures et de systèmes d'exploitation.
La taille du mot et l'\emph{endianness} peuvent notamment
varier\footnote{Les auteurs se refusent à utiliser le mot \og boutisme
  \fg\ pour désigner l'\emph{endianness}.}.
Un autre aspect essentiel du calcul distribué, et de \functory\ en
particulier, est la \emph{tolérance aux pannes}. Les ouvriers peuvent
ainsi être arrêtés, relancés, temporairement stoppés ou inatteignables
à cause de problèmes liés au réseau, sans jamais compromettre le
résultat final du calcul.

\paragraph{Une approche fonctionnelle.}
Nous avons essayé de tirer partie des spécificités de la programmation
fonctionnelle pour proposer une interface la plus générique possible.
L'une des idées principales de \functory\ est que chaque ouvrier est
une fonction potentiellement polymorphe
\begin{ocaml}
  worker: 'a -> 'b
\end{ocaml}
où \of{'a} dénote le type des tâches et \of{'b} le type des résultats.
Le patron est pour sa part une fonction à laquelle on passe la liste
des tâches initiales, ainsi qu'une fonction pour traiter les résultats :
\begin{ocaml}
  master: ('a -> 'b -> 'a list) -> 'a list -> unit
\end{ocaml}
Cette fonction passée en argument à \of{master} est appliquée dès
qu'un nouveau résultat est disponible. Elle peut produire de nouvelles
tâches (d'où son type de retour \of{'a list}), qui s'ajoutent alors à
la liste des tâches à effectuer.
Le processus complet s'achève lorsque toutes les tâches ont été
effectuées. 

Notre bibliothèque tire partie des capacités de sérialisation
d'\Ocaml\ autant que possible. Ainsi lorsque le patron et les ouvriers
sont matérialisés par le même exécutable, fonctions et valeurs
polymorphes peuvent être sérialisées, ce qui permet de réaliser
facilement le schéma ci-dessus. Il n'est cependant pas toujours
possible d'utiliser le même programme pour le patron et les
ouvriers. Dans ce cas, on peut tout de même continuer à sérialiser des
valeurs polymorphes lorsque la version d'\Ocaml\ utilisée est la même
pour tous. Sinon, on ne peut plus que transmettre des chaînes de
caractères entre les différents acteurs. La bibliothèque \functory\
s'adapte à toutes ces situations en proposant plusieurs interfaces.
 
\medskip

Cet article s'organise ainsi.
La section~\ref{sec:API} présente l'interface de la bibliothèque.
Son utilisation est alors illustrée sur des exemples dans la
section~\ref{sec:studies}.
La section~\ref{sec:implem} donne des détails techniques concernant la
réalisation de \functory. Enfin la section~\ref{sec:experiments}
montre le potentiel de cette bibliothèque sur des tests expérimentaux.
%
\functory\ est librement distribuée à l'adresse
\url{http://functory.lri.fr/}. Un rapport plus détaillé que le présent
article, en anglais, est également disponible sur ce site.

\section{Interface}\label{sec:API}
Cette section décrit l'interface de la bibliothèque \functory.
La fonctionnalité primitive est une fonction \of{compute} réalisant
l'idée principale évoquée dans l'introduction.
\begin{ocaml}
  val compute : 
    worker:('a -> 'b) -> 
    master:('a * 'c -> 'b -> ('a * 'c) list) -> 
    ('a * 'c) list -> unit
\end{ocaml}
Les tâches sont des paires, de type \of{'a * 'c}, où la première
composante sera transmise à l'ouvrier et la seconde conservée
par le patron. La fonction \of{worker} doit être observationnellement
pure et sera exécutée en parallèle par tous les ouvriers. La fonction
\of{master}, au contraire, peut être impure et sera exécutée
uniquement au sein d'un unique processus séquentiel.
Cette fonction \of{master} accumule typiquement les résultats renvoyés
par les ouvriers dans une structure locale. Elle peut en outre
produire de nouvelles tâches, 
sous la forme d'une liste de type \of{('a * 'c) list}, 
qui sont alors ajoutées aux tâches restant à effectuer.
Le troisième argument de \of{compute} est la liste des tâches
initiales, qui déclenchent le calcul.
La fonction \of{compute} rend la main lorsque toutes les tâches ont
été effectuées. Il n'y a pas de résultat renvoyé, mais uniquement des
effets de bord de la fonction \of{master}.
Nous montrerons à la fin de cette section comment en déduire des
fonctions d'ordre supérieur usuelles telles que \of{map} ou \of{fold}.

En réalité, la bibliothèque \functory\ fournit \emph{cinq}
mises en {\oe}uvre différentes de la fonction \of{compute}, correspondant à
cinq contextes d'utilisation différents.
Les deux premiers sont les plus simples.
\begin{enumerate}
\item \textbf{Exécution purement séquentielle :}
  Elle permet d'obtenir un code de référence, pour mesurer des
  performances ou mettre au point son programme.

\item \textbf{Plusieurs \coeurs\ sur une même machine :} 
  Il s'agit là de distribuer le calcul sur une unique machine,
  uniquement en créant des processus fils.
\end{enumerate}
Les trois contextes suivants correspondent à une distribution du
calcul sur un réseau de machines.
\begin{enumerate}
\setcounter{enumi}{2}
\item \textbf{Patron et ouvriers sont matérialisés par un même exécutable :}
  Cette mise en {\oe}uvre exploite la capacité d'\Ocaml\ à sérialiser
  fonctions et valeurs polymorphes de manière portable.
  Selon que le programme est exécuté comme le patron ou comme un
  ouvrier, les arguments pertinents de la fonction \of{compute} sont utilisés.

\item \textbf{Patron et ouvriers sont matérialisés par différents
    programmes, compilés avec la même version d'\Ocaml\ :} 
  Il n'est plus possible de sérialiser des fonctions mais on peut
  encore sérialiser des valeurs polymorphes.
  En conséquence, la fonction \of{compute} est présentée sous la forme
  de deux fonctions, servant respectivement à réaliser le patron et
  les ouvriers :
\vspace{-0.5em}
\begin{ocaml}
val Worker.compute : ('a -> 'b) -> unit
val Master.compute : ('a * 'c -> 'b -> ('a * 'c) list) -> ('a * 'c) list -> unit
\end{ocaml}

\item \textbf{Patron et ouvriers sont matérialisés par différents
    programmes, qui ne sont même pas compilés avec la même version
    d'\Ocaml\ :} Il n'est plus possible d'utiliser la sérialisation
  d'\Ocaml\ et la fonction \of{compute} est présentée sous la forme
  de deux fonctions ne manipulant plus que des chaînes de caractères :%
\vspace{-0.5em}
\begin{ocaml}
val Worker.compute : (string -> string) -> unit
val Master.compute : (string * 'c -> string -> (string * 'c) list) ->
                    (string * 'c) list -> unit
\end{ocaml}
\end{enumerate}
La bibliothèque \functory\ est donc organisée en trois modules :
\of{Sequential} pour le calcul purement séquentiel ; \of{Cores} pour
le calcul distribué sur plusieurs \coeurs\ d'une même machine ; et
enfin \of{Network} pour le calcul en réseau. Ce dernier module
comporte trois sous-modules, appelés respectivement \of{Same},
\of{Poly} and \of{Mono}, correspondant aux situations 3, 4 et 5 ci-dessus.

%%% derived API %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Fonctions dérivées.}\label{sec:derived}
Dans de nombreuses situations, la mise en \oeuvre\ la plus simple du
parallélisme consiste à appliquer une opération sur une liste, le
traitement de chaque élément pouvant être réaliser en parallèle.
\functory\ fournit plusieurs fonctions d'ordre supérieur
offrant du calcul parallèle sur des listes, toutes dérivées de la fonction
\of{compute}. En particulier, elles sont disponibles dans les cinq
modules décrits ci-dessus.

L'opération la plus naturelle est celle consistant à appliquer une
fonction à tous les éléments d'une liste, c'est-à-dire
\begin{ocaml}
  val map : ('a -> 'b) -> 'a list -> 'b list
\end{ocaml}
Plus subtilement, on peut combiner une fonction \of{map:'a -> 'b}
avec une fonction \of{fold:'c -> 'b -> 'c} pour calculer, à partir d'une liste
$l$  et d'un accumulateur initial $a$, la valeur finale
\begin{equation}\label{eq:map-fold}
  \of{fold} ~ ... ~ (\of{fold} ~ (\of{fold} ~ a ~ (\of{map} ~ x_1)) ~
  (\of{map} ~ x_2)) ~ ... ~ (\of{map} ~ x_n)
\end{equation}
pour une certaine permutation non spécifiée $[x_1,x_2,...,x_n]$ 
de la liste $l$.
On peut alors distinguer deux cas, selon que l'opération \of{fold} est
beaucoup moins coûteuse que l'opération \of{map}, et peut être
effectuée localement par le patron, ou qu'au contraire elle peut être
coûteuse et a donc intérêt à être effectuée en parallèle des
opérations \of{map}. La bibliothèque fournit donc deux fonctions,
correspondant à ces deux cas de figure :
\begin{ocaml}
  val map_{local,remote}_fold : map:('a -> 'b) -> fold:('c -> 'b -> 'c) -> 'c -> 'a list -> 'c   
\end{ocaml}

Dans le cas de \of{map_remote_fold}, une seule opération \of{fold}
peut être effectuée à la fois (possiblement en parallèle d'opérations
\of{map}), comme le montre l'équation~(\ref{eq:map-fold}).
Il existe cependant des situations dans lesquelles plusieurs
opérations \of{fold} peuvent être effectuées en parallèle, dès que des
résultats intermédiaires de \of{map} sont disponibles. C'est le cas
notamment lorsque l'opération \of{fold} est associative (ce qui
implique que les types \of{'b} et \of{'c} sont égaux).
Lorsque l'opération \of{fold} est de plus commutative, on peut
effectuer encore plus d'opérations \of{fold} en parallèle.
Notre interface fournit donc deux autres fonctions pour ces cas
particuliers :
\begin{ocaml}
  val map_fold_{a,ac} : map:('a -> 'b) -> fold:('b -> 'b -> 'b) -> 'b -> 'a list -> 'b 
\end{ocaml}

%\medskip
Ces cinq fonctions se dérivent facilement de la fonction \of{compute}.
On peut évidemment en imaginer d'autres, comme par exemple une variante
où seule la fonction \of{fold} est significative.
L'utilisateur de \functory\ ne devrait pas avoir de mal à les dériver
lui-même de la fonction \of{compute} ou des fonctions du type
\of{map_fold} ci-dessus.

% TODO : insister sur la simplicité de Same, pour les petits programmes
% notamment 

\section{Études de cas}\label{sec:studies}

Cette section présente plusieurs études de cas que nous avons
réalisées avec \functory. On se concentre ici sur l'utilisation de la
bibliothèque ; les résultats expérimentaux sont présentés plus loin
(section~\ref{sec:experiments}). Le code source de tous les exemples
ci-dessus est contenu dans la distribution de \functory, dans le
sous-répertoire \texttt{tests}.

\subsection{Multiplication de matrices}\label{sec:matrix}

Comme premier exemple, on considère la multiplication de deux matrices
\of{a} et \of{b}, de tailles respectives
$\of{n}\times\of{p}$ et $\of{p}\times\of{m}$. 
Le résultat sera stocké dans une matrice
\of{c} de taille $\of{n}\times\of{m}$.
On suppose que \of{a}, \of{b} et \of{c} sont contenues dans des
variables globales.
En supposant en outre \of{a} organisée en lignes et \of{b} en colonnes, une
multiplication séquentielle s'écrirait ainsi 
\begin{ocaml}
  for i = 0 to n-1 do
    for j = 0 to m-1 do
      for k = 0 to p-1 do
	c.(i).(j) <- c.(i).(j) + a.(i).(k) * b.(j).(k)
      done
    done
  done  
\end{ocaml}
l'addition et la multiplication des coefficients étant notées
respectivement $+$ et $\times$.
La complexité de ce code est clairement $O(\of{n}\times\of{m}\times\of{p})$, 

Une manière évidente de distribuer ce calcul consiste à faire de la
boucle interne sur \of{k} une tâche élémentaire.
On construit alors une liste de $\of{n} \times \of{m}$ tâches, de la
manière suivante :
\begin{ocaml}
  let tasks = 
    let l = ref [] in
    for i = 0 to n-1 do for j = 0 to m-1 do
      tasks := ((a.(i), b.(j)), (i,j)) :: !tasks
    done done;
    !l
\end{ocaml}
Chaque tâche est une paire formée d'une part d'une ligne \of{a.(i)} et
d'une colonne \of{b.(j)}, et d'autre part d'une position \of{(i,j)}.
L'ouvrier reçoit la première composante et calcule le produit scalaire.
\begin{ocaml}
  let worker (ai, bj) =
    let c = ref 0 in
    for k = 0 to p-1 do c := !c + ai.(k) * bj.(k) done;
    !c
\end{ocaml}
La patron est une fonction d'une ligne, qui reçoit le résultat \of{r}
renvoyé par l'ouvrier et remplit la matrice \of{c}, en fonction de la
position contenue dans la seconde composante de la tâche. Aucune 
nouvelle tâche n'est produite.
\begin{ocaml}
  let master (_, (i,j)) r = c.(i).(j) <- r; []
\end{ocaml}
Au final, l'ensemble du calcul est lancé par un appel à la fonction
\of{compute}.
\begin{ocaml}
  let () = compute ~worker ~master !tasks
\end{ocaml}

Utiliser la version séquentielle de \functory\ est aussi simple que
d'ajouter \of{open Sequential} au début du code. Le calcul est alors
similaire à la multiplication usuelle donnée plus haut. Cela peut être
néanmoins utile pour vérifier la correction du code avant de chercher
à distribuer le calcul.

Supposons maintenant que l'on veuille utiliser une machine 4 \coeurs\
pour effectuer le calcul. Il suffit alors de remplacer la ligne
\of{open Sequential} par les deux lignes suivantes.
\begin{ocaml}
  open Cores
  let () = set_number_of_cores 4
\end{ocaml}
Le reste du code est inchangé.

Supposons enfin que l'on souhaite utiliser plutôt des machines
présentes sur le réseau, par exemple deux machines appelées
\texttt{orcus} et \texttt{belzebuth} offrant respectivement 4 et 8 \coeurs.
Il suffit de remplacer les deux lignes de code ci-dessus par les suivantes.
\begin{ocaml}
  open Network
  let () = declare_workers ~n:4 "orcus"
  let () = declare_workers ~n:8 "belzebuth"
  open Same
\end{ocaml}
On utilise ici le sous-module \of{Same} de \of{Network}, qui permet
d'utiliser le même exécutable pour le patron et les ouvriers. Ce
module fournit toujours une fonction \of{compute} de même signature
que dans les modules \of{Sequential} et \of{Cores}, et le reste du
code est toujours inchangé. Le patron et les ouvriers sont distingués
à l'exécution par la présence de la variable d'environnement
\texttt{WORKER}. 

Si on a besoin d'écrire deux programmes différents pour le patron et
les ouvriers, pour des raisons d'incompatibilité de binaires ou tout
autre raison, l'interface de \functory\ permet de le faire.
Si les deux programmes sont compilés avec la même version d'\Ocaml, on
utilise le module \of{Poly}.
Commençons par l'ouvrier. Son code prend la forme suivante.
\begin{ocaml}
  open Network.Poly
  let worker (ai, bj) = ...
  let () = Worker.compute worker ()
\end{ocaml}
La fonction \of{Worker.compute} entre dans une boucle qui attend les
tâches envoyées par le patron et renvoie les résultats calculés par
la fonction \of{worker}. Le code du patron, quant à lui, est quasiment
le même qu'auparavant. On commence par remplacer \of{Same} par
\of{Poly}.
\begin{ocaml}
  open Network
  let () = declare_workers ~n:4 "orcus"
  let () = declare_workers ~n:8 "belzebuth"
  open Poly
\end{ocaml}
La construction des tâches et la fonction \of{master} sont inchangées.
\begin{ocaml}
  let tasks = ...
  let master (_, (i,j)) r = ...
\end{ocaml}
Enfin on lance le calcul avec la fonction \of{Master.compute}, qui ne
prend plus de fonction \of{worker} en argument.
\begin{ocaml}
  let () = Master.compute ~master tasks
\end{ocaml}

Quand le patron et les ouvriers sont compilés avec des versions
différentes d'\Ocaml, la bibliothèque fournit une interface
ne permettant plus que l'échange de chaînes de caractères.
En conséquence, il faut convertir les tâches et les résultats depuis
et vers des chaînes, dans les deux programmes.
L'ouvrier modifié prend alors la forme suivante.
\begin{ocaml}
  open Mono
  let worker (ai, bj) = ...
  let worker_string s = string_of_coeff (worker (task_of_string s))
  let () = Worker.compute worker_string ()
\end{ocaml}
Le patron est modifié de la même façon.
The master program is modified in a similar way.
On remplace \of{Poly} par \of{Mono} et on encode/décode les tâches et
résultats.
\begin{ocaml}
  let tasks = ... string_of_task ...
  let master (_, (i,j)) r = c.(i).(j) <- coeff_of_string r; []
\end{ocaml}
Les quatre fonctions de conversion \of{string_of_}\{\of{task,coeff}\} et
\{\of{task,coeff}\}\of{_of_string} sont à la charge de l'utilisateur.

\subsection{Autres études de cas}

Nous présentons ici trois autres études de cas, plus rapidement.

\paragraph{N-reines.}\label{sec:n-queens}
Il s'agit du problème classique consistant à calculer le nombre de
façons de disposer $N$ reines sur un échiquier $N\times N$ sans que
deux d'entre elles soient en prise.
On utilise un algorithme standard, consistant à positionner une reine
sur chaque ligne de l'échiquier, en partant de la première ligne. Il
est facile de distribuer le calcul: on considère toutes les façons de
placer les reines des $D$ premières lignes et on effectue le reste du
calcul en parallèle. Pour $D=1$ on obtient ainsi $N$ tâches ; pour
$D=2$ on obtient $N^2-3N+2$ tâches ; et ainsi de suite.
Chaque tâche est composée de quelques entiers et son résultat est un
entier donnant le nombre de solutions pour cette tâche.
On utilise la fonction \of{map_local_fold} où \of{map} effectue la
recherche et \of{fold} somme les résultats intermédiaires.

\paragraph{L'ensemble de Mandelbrot.}
Dessiner l'ensemble de Mandelbrot est un autre exemple de calcul
aisément distribuable, puisque la couleur de chaque point peut être
calculée indépendamment. Supposons donnée une région à dessiner, ainsi
que la taille $\of{w} \times \of{h}$ en pixels de l'image finale.
On se donne un nombre de tâches $\of{t} \ge 1$ comme paramètre. Il est
immédiat de découper l'image en \of{t} sous-images, par exemple en
bandes horizontales (si $\of{h} \ge \of{t}$) ou plus généralement en
blocs rectangulaires.
Chaque tâche est constituée de quatre nombre flottants définissant la
région à dessiner, ainsi que deux entiers donnant la taille de l'image
correspondante. Le résultat est une matrice de pixels, de taille
$(\of{w}\times\of{h}) / \of{t}$.
Ainsi, dessiner une image $800\times 600$ en utilisant 20 tâches
donnera 20 sous-images de $176\,000$ octets chacune, en supposant
chaque pixel représenté par quatre octets.

\paragraph{Démonstrateurs automatiques.}\label{sec:SMT}
Le dernier exemple correspond à celui mentionné dans l'introduction.
Il s'agit ici de vérifier la validité de 80 obligations de preuve
(OP), issues de la plate-forme Why~\cite{filliatre07cav}, à l'aide de
quatre démonstrateurs automatique de la famille SMT (à savoir
Alt-Ergo, Simplify, Z3 et CVC3).  Chaque OP est vérifiée avec chaque
démonstrateur, ce qui fait un total de 320 tâches.
Les OP sont contenues dans des fichiers accessibles par NFS et une
tâche est donc un nom de fichier et un nom de démonstrateur. 
Le démonstrateur est appelé comme un programme externe, avec un temps
d'exécution maximal. Le
résultat d'une tâche est la réponse du démonstrateur (valide, abandon,
temps limite atteint, erreur pendant l'exécution) et son temps de calcul.
Le patron collecte les résultats et les présente au final sous forme
d'une table synthétique.

\section{Détails techniques}\label{sec:implem}

Cette section décrit la réalisation des différents modules de la
bibliothèque \functory\ introduits section~\ref{sec:API}, exception
faire du module \of{Sequential}, dont la réalisation est immédiate.
%
Les deux modules \of{Cores} et \of{Network} contiennent une boucle
principale analogue, de la forme suivante :
\begin{flushleft}
  \quad  \textbf{tant que} tâches à faire $\lor$ tâches en cours \\
  \quad  \quad \textbf{tant que} tâches à faire $\land$ ouvriers disponibles \\
  \quad  \quad \quad affecter une tâche à un ouvrier \\
  \quad  \quad \textbf{attendre} la fin d'une tâche \\
  \quad  \quad \quad ajouter les nouvelles tâches renvoyées par \of{master} \\
\end{flushleft}
La différence se situe dans la technologie utilisée pour affecter une
tâche à un ouvrier, pour attendre la fin d'une tâche et enfin pour
ajouter de la tolérance aux pannes.

\subsection{\of{Cores}}

Le module \of{Cores} permet de distribuer le calcul sur une unique
machine, typiquement en exploitant plusieurs \coeurs. 
Comme illustré section~\ref{sec:studies}, la
\of{set_number_of_cores} permet de spécifier le nombre de \coeurs\ à
utiliser. Ce nombre peut être différent du nombre effectif de \coeurs\ 
de la machine. Il peut même être strictement plus grand.
En fait, ce nombre indique tout simplement combien de tâches peuvent être
effectuées simultanément.

Le module \of{Cores} est réalisé à l'aide de processus \unix, en
utilisant la fonction \of{Unix.fork} de la bibliothèque standard d'\Ocaml.
Plus précisément, un compteur indique le nombre d'ouvriers disponibles 
et l'affectation d'une tâche à un ouvrier se fait en 
créant un nouveau sous-processus avec \of{fork}.
À la fin du calcul, le résultat de la tâche est transmis au processus
père par sérialisation dans un tube.
La répartition des tâches sur les différents \coeurs\ (physiques) de
la machine, le cas échéant, est laissée au système. Il se peut donc
que deux tâches se retrouvent être exécutées sur le même \coeur, y
compris dans le cas où le nombre de \coeurs\ déclarés est inférieur ou
égal au nombre de \coeurs\ effectifs.

\subsection{\of{Network}}

Le module \of{Network} permet de distribuer le calcul sur un réseau de
machines. 
Comme illustré section~\ref{sec:studies}, la fonction 
\of{declare_workers: n:int -> string -> unit} permet de déclarer
l'ensemble des machines du réseau sur lesquels se trouvent des
ouvriers, en spécifiant un nombre d'ouvriers par machine (qui 
ne coïncide pas nécessairement avec un nombre effectif de \coeurs).
Le module \of{Network} est basé sur une architecture client/serveur
utilisant TCP/IP, où chaque ouvrier est un serveur et où le patron
est (ironiquement) le client de chaque ouvrier.

\paragraph{Protocole.}\label{sec:protocol}
Le protocole utilisé comporte sept messages différents.
Les quatre messages possibles envoyés par le patron à un ouvrier sont : 
\of{Assign(id:int, f:string, x:string)} pour affecter une nouvelle
tâche \of{id} à l'ouvrier, sous la forme de deux chaînes \of{f} et \of{x} dont
le sens dépend du contexte ; 
\of{Kill(id:int)} pour demander l'interruption de la tâche \of{id} ;
\of{Stop} pour demander l'arrêt définitif de l'ouvrier ;
et enfin \of{Ping} pour vérifier que l'ouvrier est toujours réactif.
Inversement, les trois messages possibles envoyés par un ouvrier au
patron sont :
\of{Pong} en réponse à un message \of{Ping} ;
\of{Completed(id:int, s:string)} pour renvoyer le résultat \of{s} de
la tâche \of{id} ;
et enfin \of{Aborted(id:int)} pour signifier l'échec de la tâche
\of{id}, soit en réponse à \of{Kill}, soit à cause d'une erreur lors
de l'exécution de la fonction \of{worker}.

Ce protocole est de telle
sorte que patron et ouvriers peuvent être exécutés sur des
plate-formes complètement différentes, vis-à-vis de
l'\emph{endianness}, de la version d'\Ocaml\ et du système d'exploitation.
Dans le sous-module \of{Same}, les arguments \of{f} et \of{x} du
message \of{Assign} désignent respectivement
la sérialisation d'une fonction et de
son argument, et l'argument \of{s} du message \of{Completed} la
sérialisation du résultat. Dans les sous-module \of{Poly} et
\of{Mono}, en revanche, la
partie \of{f} du message \of{Assign} n'est plus pertinente
car la fonction \of{worker} est maintenant locale à l'ouvrier.
Les chaînes \of{x} et \of{s} restent pertinentes ; pour \of{Poly},
ce sont des sérialisations de valeurs \Ocaml\ et pour \of{Mono}  de
simples chaînes de caractères.


\subsubsection{Tolérance aux pannes}\label{sec:fault}

L'une des principales difficultés dans un environnement de calcul
distribué est la tolérance aux pannes. C'est l'un des principaux
atouts de la bibliothèque \functory.
Les pannes concernent ici uniquement le module \of{Network} et sont de
deux sortes : un ouvrier peut être stoppé et éventuellement plus tard
redémarré ; ou un ouvrier peut être temporairement ou définitivement
inaccessible sur le réseau. Dans tous les cas, on souhaite que le
calcul parvienne à son terme, dès lors que cela reste possible, et
idéalement en utilisant au mieux les ressources disponibles.

Pour assurer cette tolérance aux pannes, le patron maintient en
permanence l'état de chaque ouvrier. Cet état est contrôlé par deux
délais $T_1$ et $T_2$, paramétrés par l'utilisateur,
et par l'ensemble des messages échangés.
Il y a quatre états possibles pour un ouvrier :
\of{déconnecté} signifie qu'il n'y a pas de connection TCP en cours
entre le patron et l'ouvrier ; 
\of{vivant} signifie qu'un message de l'ouvrier a été reçu par le patron
il y a moins de $T_1$ secondes ;
\of{contacté} signifie que l'ouvrier n'a pas envoyé de message depuis
plus de $T_1$ secondes et que le patron lui a envoyé un message
\of{Ping} depuis moins de $T_2$ secondes ;
enfin \of{inatteignable} signifie que l'ouvrier n'a toujours pas répondu au
message \of{Ping} (depuis plus de $T_2$ secondes).
Dès qu'un message est reçu en provenance d'un ouvrier, son état est
mis à jour. On a donc l'automate suivant pour les états d'un ouvrier donné.
\begin{center}
  \includegraphics{state.mps}
\end{center}

La tolérance aux pannes est réalisée en exploitant l'état des ouvriers
de la manière suivante. Les tâches ne sont envoyées qu'à des ouvriers
se trouvant dans l'état \of{vivant} ou \of{contacté}.
D'autre part, dès qu'un ouvrier en train d'effectuer une tâche $t$
passe dans l'état \of{déconnecté} ou \of{inatteignable}, la tâche $t$
et reprogrammée, ce qui signifie qu'elle est ajoutée de nouveau à
l'ensemble des tâches restant à effectuer. Lorsque le patron reçoit un
résultat pour une tâche $t$, il déprogramme la tâche $t$ si elle avait
été reprogrammée et indique à tout ouvrier ayant déjà entrepris de
recalculer $t$ de cesser son travail (avec le message \of{Kill}).

\section{Résultats expérimentaux}\label{sec:experiments}

Cette section présente quelques résultats expérimentaux obtenus avec
les quatre programmes décrits section~\ref{sec:studies}.

\paragraph{N-reines.}
La table suivant montre les temps d'exécution pour différentes valeurs
de $N$ et pour chacun des trois modules \of{Sequential}, \of{Cores} et
\of{Network}. L'objectif est ici de mesurer le facteur par rapport à
l'exécution séquentielle. En conséquence, tous les calculs sont
effectués sur la même machine, un Intel Xeon 8 \coeurs\ 3.2 GHz sous
Linux Debian. L'exécution séquentielle utilise un unique \coeur. La
version multi-\coeurs\ utilisent les 8 \coeurs\ de la machine. La
version réseau utilise également 8 ouvriers locaux à la machine, le
patron s'exécutant sur une machine distante pour induire des
communications réseaux réalistes.
La première colonne donne la valeur de $N$ et la seconde le nombre de
tâches. Les trois colonnes suivantes donnent les temps d'exécution, en
secondes, et le facteur d'accélération entre parenthèses.
\begin{center}
  \begin{tabular}{|r|r|r|r|r|}
    \hline
    N & \#tâches  & \of{Sequential}& \of{Cores}                 & \of{Network} 
    \\\hline\hline
    16 &   16    &  15.2     &   2.04 (7.45$\times$) &  2.35  (6.47$\times$) 
    \\\hline
       &  210    &  15.2     &   2.01 (7.56$\times$) & 21.80  (0.69$\times$)
    \\\hline
    17 &   17    & 107.0     &  17.20 (6.22$\times$) & 16.20  (6.60$\times$)
    \\\hline
       &  240    & 107.0     &  14.00 (7.64$\times$) & 24.90  (4.30$\times$)
    \\\hline
    18 &   18    & 787.0     & 123.00 (6.40$\times$) & 125.00 (6.30$\times$)  
    \\\hline
       &  272    & 787.0     & 103.00 (7.64$\times$) & 124.00 (6.34$\times$)  
    \\\hline
    19 &   19    &6120.0     & 937.00 (6.53$\times$) & 940.00 (6.51$\times$)  
    \\\hline
       &  306    &6130.0     & 796.00 (7.70$\times$) & 819.00 (7.48$\times$)
    \\\hline
  \end{tabular}
\end{center}
From the table above, it is clear that the \of{Cores} and \of{Network}
implementations provide a significant speedup. As evident from the
last row, the speedup is almost 8, which is also the number of
cores we use.  It is also evident from the last column that the
\of{Network} implementation performs significantly better when the
computation time dominates in the total execution time.  The two extreme
cases correspond to the second and the last row: in the second row, the
communication time dominates and is in fact more than 91\%\ of the
total execution time; on the other hand, for the last row
communication time amounts to just 4.6\%\ of the total execution time.
As expected, the network implementation is only beneficial when the
computation time for each individual task is significant, which is the
case in realistic examples.

\subsection{Mandelbrot Set}

This benchmark consists in drawing the fragment of the Mandelbrot set
with lower left corner $(-1.1, 0.2)$ and upper right corner $(-0.8,
0.4)$, as a $9,000\times6,000$ image. The sequential computation of
this image consumes 29.4 seconds. For \of{Cores} and \of{Network}
implementations, the computation times in seconds are tabulated below.

% TODO compute ratios for Network
\begin{center}
  \begin{tabular}{|r|r|r|r|r|}
    \hline
    \#cores  &\#tasks & \of{Cores} & \of{Network} \\
    \hline\hline
    2       & 10 & 15.8       (1.86) &  20.3       \\
            & 30 & 15.7       (\underline{1.87}) &  18.7       \\
            & 100 & 16.1      (1.83) &  19.8       \\
            & 1000 & 19.6     (1.50) &  38.6      \\
    \hline
    4       & 10 & 9.50       (3.09)  &  14.4       \\
            & 30 & 8.26       (\underline{3.56})  &  11.4   \\
            & 100 & 8.37      (3.51)  &  11.4   \\
            & 1000 & 10.6     (2.77)  &  20.5    \\
    \hline
    8       & 10 & 9.40       (3.13)  &  12.6      \\
            & 30 & 4.24       (\underline{6.93})  &   7.6      \\
            & 100 & 4.38      (6.71)  &   7.5      \\
            & 1000 & 6.86     (4.29)  &  11.3      \\
    \hline
  \end{tabular}
\end{center}
The best timings are achieved for the \of{Cores} configuration, where
communications happen within the same machine and are thus cheaper.
There are two significant differences with respect to the n-queens
benchmark.  On one hand, the number of tasks can be controlled more
easily than in the case of n-queens. We experimentally figured out the
optimal number of tasks to be 30. One the other hand, each computation
result is an image, rather than just an integer as in the case of
n-queens. Consequently, communication costs are much greater. 
In this particular experiment, the total size of the results
transmitted is more than 200 Mb.

\subsection{Matrix Multiplication}

This benchmark was inspired by the PASCO'10 programming contest~\cite{PASCO}.
It consists of multiplication of
two square matrices of dimension 100, that is $\of{n} = \of{p} =
\of{m} = 100$, with integer coefficients.
Coefficients have several thousands of digits, hence we use
GMP~\cite{GMP} to handle operations over coefficients.

We compare the performances of two different implementations. In the
first one, called \of{mm1}, each task consists of the computation of a single
coefficient of the resultant matrix, as described in Section~\ref{sec:matrix}.
In the second one, called \of{mm2}, each task consists of the
computation of a whole row of the resultant matrix.
As a consequence, the total number of tasks in
$\of{n}\times\of{m}=10,000$ for \of{mm1} and only $\of{n}=100$ for \of{mm2}.
The experimental results (in seconds) are tabulated below.
\begin{center}
  \begin{tabular}{|r|r|r|}
    \hline
    & \of{mm1}       & \of{mm2}  \\
    & (10,000 tasks) & (100 tasks) \\
    \hline\hline
\of{Sequential} & 20.3 \phantom{(0.00)} &  20.2 \phantom{(0.00)} \\
\hline
 \of{Cores} 
 (2 cores)     &   22.7 (0.89) &  11.3 (1.79) \\
 (4 cores)     &   12.3 (1.65) &   6.1 (3.31) \\
 (6 cores)     &    8.6 (2.36) &   4.3 (4.70) \\
 (8 cores)     &    8.0 (2.54) &   3.5 (\underline{5.77}) \\
 \hline
  \end{tabular}
\end{center}
We do not include results for the network configuration, as they do
not achieve any benefit with respect to the sequential
implementation. The reason is that the communication cost dominates the
computation cost in such a way that the total execution time is
always greater than 30 seconds. Indeed, irrespective of the
implementation (\of{mm1} or \of{mm2}), the total size of the
transmitted data is 
$O(\of{n}\times\of{m}\times\of{p})$, which in our case amounts to
billions of bytes.

A less naive implementation would have the worker read the input matrices
only once, \emph{e.g.} from a file, and then have the master send only
row and column indices. This would reduce the communication cost to
$O(\of{n}\times\of{m})$ only.

%             mm1     mm2

% # tasks    10,000   100

% sequential  20.3   20.2

% cores 2     22.7   11.3
% cores 4     12.3    6.1
% cores 6      8.6    4.3
% cores 8      8.0    3.5

% network = workers on moloch + master on belzebuth

% cores 2     93     32.3
% cores 4     87     33.7
% cores 6     92     33.5
% cores 8     88     32.5




\subsection{SMT Solvers}

As explained in Section~\ref{sec:SMT}, this benchmark consists of 80
verification conditions, each being checked by 4 different SMT
solvers. Each task is executed with a timeout limit of 1 minute.
Our computing
infrastructure for this experiment consists of 3 machines with 4, 8 and 8 cores
respectively. 
The figure below shows the total time in minutes spent by each prover
for each possible outcome.
\begin{center}
  \begin{tabular}{|r||r|r|r|r|}
    \hline
    prover   & valid & unknown & timeout & failure
    \\\hline\hline
    Alt-ergo & 406.0 & 3.0   &  11400.0 & 0.0       
    \\\hline
    Simplify &  0.5   & 0.4   &  1200.0 & 222.0   
    \\\hline
    Z3       & 80.7   & 0.0   &  1800.0 & 1695.0   
    \\\hline
    CVC3     & 303.0  & 82.7  &  4200.0 & 659.0   
    \\\hline
  \end{tabular}
\end{center}
These figures sum up to more than 6 hours if provers were executed
sequentially. However, using our library and our 3-machine
infrastructure, it completes in 22 minutes and 37 seconds, giving us a
speedup of more than 16$\times$. We are still far away from the ideal
ratio of 20$\times$ (we are using 20 cores), since some provers are
allocating a lot of memory and time spent in system calls is not
accounted for in the total observed time. However, a ratio of
16$\times$ is already a significant improvement for our day-to-day
experiments. 

\section{Conclusion et perspectives}\label{sec:future}

We presented a distributed programming environment for functional
programming. The main features are the genericity of the interface,
which makes use of polymorphic higher-order functions, and the ability
to easily switch between sequential, multi-core, and network
implementations. In particular, \functory\ allows to use the same
executable for master and workers, which makes the deployment of small programs
immediate --- master and workers being only distinguished by an
environment variable. \functory\ also allows master and workers to be
completely different programs, which is ideal for large scale deployment.
Another distinguishing feature of our library is a
robust fault-tolerance mechanism which relieves
the user of cumbersome implementation details.
Finally, \functory\ also allows to cascade several distributed
computations inside the same program.

\paragraph{Related Work.}
Closest to the approach in this paper is Yohann Padioleau's MapReduce
implementation in \Ocaml~\cite{poor-man-mapreduce}.  It is built on
top of OCamlMPI~\cite{ocamlMPI}, while our approach uses a homemade
protocol for message passing.  Currently, we have less flexibility
w.r.t. deployment of the user program than OCamlMPI; on the other
hand, we provide a 
more generic API together with fault tolerance.  There are other
distributed computing libraries on top of which one could implement
the library discussed in this paper. \JoCaml~\cite{jocaml} is one of
them. However, \JoCaml\ does not provide fault tolerance, which is
indispensable in a distributed setting. The user has to include code
for fault tolerance, as already demonstrated in some \JoCaml\
experiments~\cite{mandel2008}. 

There are other implementations of distributed computing in the
context of functional programming. One is the Disco
project~\cite{disco}, which implements exactly Google's MapReduce in
Erlang~\cite{erlang}. Our library, on the contrary, is not an \Ocaml\
implementation of Google's MapReduce.
There are other ways to exploit multi-core architectures. One of these
is data parallelism, which is also relevant in the functional
programming setting~\cite{parallel-haskell}. Our work
does not target data parallelism at all.

\paragraph{Future Work.}
There are still some interesting features that could be added to our
library. 
\begin{itemize}
\item 
  One is the ability to efficiently assign tasks to workers depending
  on resource parameters, such as data locality, CPU power, memory,
  etc. This could be achieved by providing the user with the means to control
  task scheduling.  
\item 
  Another interesting feature could be the ability
  to add or remove machines dynamically. Currently, our library assumes
  that the list of machines to be used is given \emph{a priori}, as
  part of the code. An alternative would be to read machine names from
  a file, watched periodically by the master.
\item
  Our library provides limited support for displaying real-time
  information about computations and communications. Processing and storing
  information about workers and tasks locally in the master is straightforward; 
  monitoring it in real-time could be done using
  \textsf{Ocamlviz}~\cite{ocamlviz}. 
\item 
  One very nice feature of Google's MapReduce is the possibility to
  use redundantly several idle workers on the same tasks
  for speedup when reaching the end of computation.
  Since we already have the fault tolerance implemented, this
  optimization should be straightforward to add to our library.
\end{itemize}
We intend to enrich our library with all above features.

%\appendix


\paragraph{Remerciements.}
Les auteurs remercient Alain Mebsout et Johannes Kanig pour avoir testé
la bibliothèque \functory\ et pour leurs commentaires.

%\vfill\pagebreak
\bibliographystyle{plain}
\bibliography{./biblio}

\end{document}

% LocalWords:  parallelize functor parameterized indices endianness monomorphic
% LocalWords:  genericity executables OCamlMPI MapReduce généricité marshalling

%%% Local Variables: 
%%% mode: latex
%%% ispell-local-dictionary: "francais"
%%% TeX-master: t
%%% End: 

% LocalWords:  sérialisation boutisme inatteignables observationnellement
% LocalWords:  sous-modules sérialisations
